# This repository is dedicated to following research that combines medical image analysis models and large language models (LLMs).
## Large Language Models (LLMs)
- [GPT-4.](https://cdn.openai.com/papers/gpt-4.pdf) (March 14, 2023)
- [Standford Alpaca.](https://github.com/tatsu-lab/stanford_alpaca) (March 14, 2023)
- [Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models.](https://arxiv.org/abs/2303.04671) (March 8, 2023)
- [LLaMA: Open and Efficient Foundation Language Models.](https://arxiv.org/abs/2302.13971v1) (February 27, 2023)
- [BioMedLM GPT](https://crfm.stanford.edu/2022/12/15/pubmedgpt.html)

## Vision Language Models (VLMs)
- [ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks.](https://proceedings.neurips.cc/paper/2019/hash/c74d97b01eae257e44aa9d5bade97baf-Abstract.html) (2019)
- [UNITER: UNiversal Image-TExt Representation Learning](https://link.springer.com/chapter/10.1007/978-3-030-58577-8_7) (2020)
- [Perceiver: General Perception with Iterative Attention](http://proceedings.mlr.press/v139/jaegle21a.html) (2021)
- [Learning to Prompt for Vision-Language Models](https://link.springer.com/article/10.1007/s11263-022-01653-1) (2022)
- [VLMo: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts](https://proceedings.neurips.cc/paper_files/paper/2022/hash/d46662aa53e78a62afd980a29e0c37ed-Abstract-Conference.html) (2022)
- [An Empirical Study of Training End-to-End Vision-and-Language Transformers](https://openaccess.thecvf.com/content/CVPR2022/html/Dou_An_Empirical_Study_of_Training_End-to-End_Vision-and-Language_Transformers_CVPR_2022_paper.html) (2022)
- [Flamingo: a Visual Language Model for Few-Shot Learning](https://proceedings.neurips.cc/paper_files/paper/2022/hash/960a172bc7fbf0177ccccbb411a7d800-Abstract-Conference.html) (2022)
- [PaLM-E: An Embodied Multimodal Language Model.](https://arxiv.org/abs/2303.03378)
- [VQA: Visual Question Answering.](https://openaccess.thecvf.com/content_iccv_2015/papers/Antol_VQA_Visual_Question_ICCV_2015_paper.pdf)

## Prompt Engineering
- [Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference](https://arxiv.org/abs/2001.07676) (2021)
- [It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners](https://arxiv.org/abs/2009.07118) (2021)
- [AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts](https://arxiv.org/abs/2010.15980) (2020)
- [Calibrate Before Use: Improving Few-shot Performance of Language Models](http://proceedings.mlr.press/v139/zhao21c.html) (2021)
- [The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/abs/2104.08691) (2021)
- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903) (January 10, 2023)
- [How Does In-Context Learning Help Prompt Tuning?](https://arxiv.org/pdf/2302.10198.pdf)
- [WARP: Word-level Adversarial ReProgramming.](https://arxiv.org/pdf/2101.00121.pdf)

## Large Language Models for Medicine
- [ChatGPT: the future of discharge summaries?](https://www.thelancet.com/journals/landig/article/PIIS2589-7500(23)00021-3/fulltext)
- [ChatCAD: Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models.](https://arxiv.org/abs/2302.07257)
- [The Diagnostic and Triage Accuracy of the GPT-3 Artificial Intelligence Model.](https://www.medrxiv.org/content/10.1101/2023.01.30.23285067v1)

## Large Vision Models
- [Scaling Vision Transformers to 22 Billion Parameters](https://arxiv.org/abs/2302.05442) (February 10, 2023)

## Text Augmentation
- [ChatAug: Leveraging ChatGPT for Text Data Augmentation.](https://arxiv.org/abs/2302.13007)
